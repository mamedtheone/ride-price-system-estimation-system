{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ride Price Estimation System\n",
    "\n",
    "This notebook walks through dataset creation, cleaning, feature engineering, and modeling (linear regression + logistic regression) for estimating ride prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ML Mindset & Problem Framing\n",
    "- **Learning problem:** Predict continuous ride prices using trip context features.\n",
    "- **Why ML instead of fixed rules?** Real-world pricing depends on interacting factors (traffic, weather, demand) that change over time. ML can learn these patterns from data.\n",
    "- **What the model should learn:** The relationship between trip/context features and observed ride prices so it can generalize to new rides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration & Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/rides.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ride_price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(df['distance_km'], df['ride_price'], alpha=0.7)\n",
    "plt.title('Ride price vs distance')\n",
    "plt.xlabel('Distance (km)')\n",
    "plt.ylabel('Ride price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning & Feature Engineering\n",
    "**Missing values:** fill numeric features with median and categorical features with mode.\n",
    "**Outliers:** cap distance and duration using the IQR rule to reduce extreme influence.\n",
    "**Encoding & scaling:** One-hot encode categoricals and standardize numeric features.\n",
    "\n",
    "Poor data quality (missing values, mislabeled categories, or extreme outliers) can bias the model and reduce generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "\n",
    "# handle missing values\n",
    "for col in ['distance_km', 'duration_min']:\n",
    "    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "    df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
    "\n",
    "for col in ['time_of_day', 'traffic_level', 'weather', 'demand_level', 'day_of_week']:\n",
    "    df_clean[col] = df_clean[col].replace('', np.nan)\n",
    "    df_clean[col] = df_clean[col].fillna(df_clean[col].mode()[0])\n",
    "\n",
    "# outlier treatment using IQR\n",
    "for col in ['distance_km', 'duration_min']:\n",
    "    q1 = df_clean[col].quantile(0.25)\n",
    "    q3 = df_clean[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    df_clean[col] = df_clean[col].clip(lower, upper)\n",
    "\n",
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Justification\n",
    "- **distance_km:** Longer rides cost more due to fuel/time.\n",
    "- **duration_min:** Captures slow traffic or longer routes affecting price.\n",
    "- **time_of_day:** Peak hours tend to be pricier.\n",
    "- **traffic_level:** High congestion increases duration and cost.\n",
    "- **weather:** Bad weather can increase demand and risk.\n",
    "- **demand_level:** Surge pricing occurs when demand exceeds supply.\n",
    "- **day_of_week:** Weekends often have different demand patterns.\n",
    "\n",
    "**Feature not included:** Driver rating was considered, but pricing should not depend on individual driver behavior in a fair pricing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regression Model: Price Prediction (Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode categoricals\n",
    "X = pd.get_dummies(df_clean.drop(columns=['ride_price']), drop_first=True).astype(float)\n",
    "y = df_clean['ride_price'].values.reshape(-1, 1)\n",
    "\n",
    "# standardize numeric columns\n",
    "numeric_cols = ['distance_km', 'duration_min']\n",
    "X[numeric_cols] = (X[numeric_cols] - X[numeric_cols].mean()) / X[numeric_cols].std()\n",
    "\n",
    "# train-test split\n",
    "rng = np.random.default_rng(42)\n",
    "indices = np.arange(len(X))\n",
    "rng.shuffle(indices)\n",
    "split = int(len(X) * 0.8)\n",
    "train_idx, test_idx = indices[:split], indices[split:]\n",
    "\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "# add bias term\n",
    "X_train_bias = np.c_[np.ones((X_train.shape[0], 1)), X_train.values]\n",
    "X_test_bias = np.c_[np.ones((X_test.shape[0], 1)), X_test.values]\n",
    "\n",
    "# closed-form solution (normal equation)\n",
    "theta = np.linalg.pinv(X_train_bias.T @ X_train_bias) @ X_train_bias.T @ y_train\n",
    "y_pred = X_test_bias @ theta\n",
    "\n",
    "mae = np.mean(np.abs(y_test - y_pred))\n",
    "ss_res = np.sum((y_test - y_pred) ** 2)\n",
    "ss_tot = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "r2 = 1 - ss_res / ss_tot\n",
    "mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Predicted vs Actual Ride Prices')\n",
    "min_val = min(y_test.min(), y_pred.min())\n",
    "max_val = max(y_test.max(), y_pred.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Classification Model: High-Cost vs Low-Cost Ride (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = df_clean['ride_price'].median()\n",
    "y_cls = (df_clean['ride_price'] >= threshold).astype(int).values.reshape(-1, 1)\n",
    "\n",
    "# reuse encoded features from regression\n",
    "X_cls = X\n",
    "X_train, X_test = X_cls.iloc[train_idx], X_cls.iloc[test_idx]\n",
    "y_train, y_test = y_cls[train_idx], y_cls[test_idx]\n",
    "\n",
    "X_train_bias = np.c_[np.ones((X_train.shape[0], 1)), X_train.values]\n",
    "X_test_bias = np.c_[np.ones((X_test.shape[0], 1)), X_test.values]\n",
    "\n",
    "# logistic regression via gradient descent\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "theta = np.zeros((X_train_bias.shape[1], 1))\n",
    "lr = 0.1\n",
    "epochs = 2000\n",
    "\n",
    "for _ in range(epochs):\n",
    "    preds = sigmoid(X_train_bias @ theta)\n",
    "    gradient = (X_train_bias.T @ (preds - y_train)) / len(y_train)\n",
    "    theta -= lr * gradient\n",
    "\n",
    "probs = sigmoid(X_test_bias @ theta)\n",
    "y_pred = (probs >= 0.5).astype(int)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "confusion = pd.crosstab(y_test.flatten(), y_pred.flatten(), rownames=['Actual'], colnames=['Predicted'])\n",
    "accuracy, confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probability explanation:** Logistic regression outputs probabilities (0-1). A threshold (usually 0.5) converts probabilities into high/low cost labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation & Comparison\n",
    "- Regression evaluates numeric price accuracy (MAE/RÂ²).\n",
    "- Classification evaluates correct high/low cost predictions (accuracy + confusion matrix).\n",
    "- Data quality issues like missing values or extreme outliers can harm both models by skewing the learned relationships.\n",
    "- The most influential feature can be approximated by inspecting linear coefficients (distance and duration are typically strongest)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Ethical & Practical Reflection\n",
    "- **Potential unfair pricing behavior:** If demand is consistently higher in certain neighborhoods, surge pricing could disproportionately impact residents there.\n",
    "- **Real-world risk:** Over-reliance on model outputs could lead to poor pricing during unusual events (storms, outages).\n",
    "- **Dataset limitation:** Synthetic data may not capture all real-world variability and bias."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
